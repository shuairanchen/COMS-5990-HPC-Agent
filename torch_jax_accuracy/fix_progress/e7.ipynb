{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3fa3a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions after loading: tensor([[3.3646],\n",
      "        [4.2802],\n",
      "        [5.1959]])\n"
     ]
    }
   ],
   "source": [
    "#Input\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Create and train the model\n",
    "torch.manual_seed(42)\n",
    "model = SimpleModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "X = torch.rand(100, 1)\n",
    "y = 3 * X + 2 + torch.randn(100, 1) * 0.1\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X)\n",
    "    loss = criterion(predictions, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Save the model to a file named \"model.pth\"\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "# Load the model back from \"model.pth\"\n",
    "loaded_model = SimpleModel()\n",
    "loaded_model.load_state_dict(torch.load(\"model.pth\"))\n",
    "loaded_model.eval()\n",
    "\n",
    "# Verify the model works after loading\n",
    "X_test = torch.tensor([[0.5], [1.0], [1.5]])\n",
    "with torch.no_grad():\n",
    "    predictions = loaded_model(X_test)\n",
    "    print(f\"Predictions after loading: {predictions}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ec2c538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 9.0799\n",
      "Epoch [20/100], Loss: 5.5066\n",
      "Epoch [30/100], Loss: 3.3760\n",
      "Epoch [40/100], Loss: 2.1048\n",
      "Epoch [50/100], Loss: 1.3452\n",
      "Epoch [60/100], Loss: 0.8905\n",
      "Epoch [70/100], Loss: 0.6173\n",
      "Epoch [80/100], Loss: 0.4523\n",
      "Epoch [90/100], Loss: 0.3518\n",
      "Epoch [100/100], Loss: 0.2898\n",
      "Predictions after loading: [[3.3005486]\n",
      " [4.0336018]\n",
      " [4.7666545]]\n"
     ]
    }
   ],
   "source": [
    "#Strong LLM\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pickle\n",
    "\n",
    "\n",
    "key = jax.random.PRNGKey(42)\n",
    "key, subkey = jax.random.split(key)\n",
    "X = jax.random.uniform(subkey, shape=(100, 1))  # 100 data points in [0, 1)\n",
    "key, subkey = jax.random.split(key)\n",
    "y = 3 * X + 2 + 0.1 * jax.random.normal(subkey, shape=(100, 1))  # y = 3*x + 2 + noise\n",
    "\n",
    "def predict(params, x):\n",
    "    \"\"\"Linear model: y = x * w + b\"\"\"\n",
    "    return jnp.dot(x, params[\"w\"]) + params[\"b\"]\n",
    "\n",
    "def loss_fn(params, X, y):\n",
    "    preds = predict(params, X)\n",
    "    return jnp.mean((preds - y) ** 2)\n",
    "\n",
    "# Initialize weight and bias. Here, weight is initialized with small random values and bias as zeros.\n",
    "key, subkey = jax.random.split(key)\n",
    "params = {\n",
    "    \"w\": 0.1 * jax.random.normal(subkey, shape=(1, 1)),\n",
    "    \"b\": jnp.zeros((1,))\n",
    "}\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(params, X, y)\n",
    "    params[\"w\"] = params[\"w\"] - lr * grads[\"w\"]\n",
    "    params[\"b\"] = params[\"b\"] - lr * grads[\"b\"]\n",
    "    # Optionally, print loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {float(loss):.4f}\")\n",
    "\n",
    "with open(\"model.pth\", \"wb\") as f:\n",
    "    pickle.dump(params, f)\n",
    "\n",
    "with open(\"model.pth\", \"rb\") as f:\n",
    "    loaded_params = pickle.load(f)\n",
    "\n",
    "X_test = jnp.array([[0.5], [1.0], [1.5]])\n",
    "predictions = predict(loaded_params, X_test)\n",
    "print(\"Predictions after loading:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a66f29dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions after training: [[-0.31621063]\n",
      " [-0.73144114]\n",
      " [-1.1466718 ]]\n"
     ]
    }
   ],
   "source": [
    "#Weak LLM\n",
    "import jax.numpy as jnp  # MODIFIED: Consistently import jax.numpy as jnp\n",
    "from jax import grad, jit, random, vmap\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "import pickle\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    \"\"\"A simple neural network model using Flax.\"\"\"\n",
    "    \n",
    "    def setup(self):\n",
    "        \"\"\"Define the layers of the model.\"\"\"\n",
    "        self.dense = nn.Dense(features=1)  # A layer with one output feature\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"Forward pass of the model.\"\"\"\n",
    "        return self.dense(x)\n",
    "\n",
    "def train_model(X, y):\n",
    "    \"\"\"Train the model with the given data.\"\"\"\n",
    "    model = SimpleModel()\n",
    "    params = model.init(random.PRNGKey(0), X)\n",
    "    # Loss function and optimization setup\n",
    "    loss_fn = lambda params: jnp.mean((model.apply(params, X) - y) ** 2)\n",
    "    optimizer = optax.adam(0.001)\n",
    "    opt_state = optimizer.init(params)\n",
    "    \n",
    "    for epoch in range(100):  # Simple training loop\n",
    "        loss, grads = jax.value_and_grad(loss_fn)(params)\n",
    "        updates, opt_state = optimizer.update(grads, opt_state)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "    \n",
    "    return params\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the training and evaluation of the model.\"\"\"\n",
    "    X_train = jnp.array([[0.0], [1.0], [2.0], [3.0]])  # Training data\n",
    "    y_train = jnp.array([[0.0], [2.0], [4.0], [6.0]])  # Expected outputs\n",
    "\n",
    "    # Train the model\n",
    "    trained_params = train_model(X_train, y_train)\n",
    "\n",
    "    # Verify the model works after loading\n",
    "    X_test = jnp.array([[0.5], [1.0], [1.5]])  # Test data\n",
    "    model = SimpleModel()  # Initialize model\n",
    "    predictions = model.apply(trained_params, X_test)  # Get predictions\n",
    "    print(f\"Predictions after training: {predictions}\")\n",
    "\n",
    "if __name__ == \"__main__\":  # Entry point for the program\n",
    "    main()  # Execute the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f45127",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Error Code:\n",
    "loss, grads = jax.value_and_grad(loss_fn)(params)\n",
    "\n",
    "\n",
    "Error:\n",
    "The entire jax module is not imported, and jax.value_and_grad is not found\n",
    "\n",
    "\n",
    "Fix Guide:\n",
    "Added import jax\n",
    "\n",
    "\n",
    "Correct Code:\n",
    "import jax\n",
    "\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(params)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Error Code:\n",
    "# Train the model\n",
    "trained_params = train_model(X_train, y_train)\n",
    "\n",
    "\n",
    "Error:\n",
    "JAX code does not implement saving and loading of model parameters\n",
    "\n",
    "\n",
    "Fix Guide:\n",
    "Use pickle to save the trained parameters to a file, then load it back and use the loaded parameters for prediction\n",
    "\n",
    "\n",
    "Correct Code:\n",
    "# Train the model\n",
    "trained_params = train_model(X_train, y_train)\n",
    "\n",
    "# Save model parameters to file\n",
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(trained_params, f)\n",
    "\n",
    "# Load model parameters from file\n",
    "with open(\"model.pkl\", \"rb\") as f:\n",
    "    loaded_params = pickle.load(f)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Error Code:\n",
    "X_train = jnp.array([[0.0], [1.0], [2.0], [3.0]])  # Training data\n",
    "y_train = jnp.array([[0.0], [2.0], [4.0], [6.0]])  # Expected outputs\n",
    "\n",
    "\n",
    "Error:\n",
    "The training data in the PyTorch code is randomly generated and noise is added according to the formula y = 3 * X + 2. The training data in the JAX code is fixed to 4 points, which is inconsistent with the data in PyTorch.\n",
    "\n",
    "\n",
    "Fix Guide:\n",
    "Use JAX's random number generator to generate 100 samples of input data and construct a target value that meets y = 3 * X + 2 + noise\n",
    "\n",
    "\n",
    "Correct Code:\n",
    "key = random.PRNGKey(42)\n",
    "key, subkey = random.split(key)\n",
    "X_train = random.uniform(subkey, (100, 1))\n",
    "key, subkey = random.split(key)\n",
    "noise = random.normal(subkey, (100, 1)) * 0.1\n",
    "y_train = 3 * X_train + 2 + noise\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Error Code:\n",
    "params = model.init(random.PRNGKey(0), X)\n",
    "\n",
    "\n",
    "Error:\n",
    "A hardcoded PRNG key is used in the train_model function, while a key has been generated based on the seed 42 in the main function.\n",
    "\n",
    "\n",
    "Fix Guide:\n",
    "Modify the train_model function to accept key as a parameter and use the passed key to initialize the model\n",
    "Pass the generated key when calling in main\n",
    "\n",
    "\n",
    "Correct Code:\n",
    "def train_model(X, y, key):\n",
    "    model = SimpleModel()\n",
    "    params = model.init(key, X)\n",
    "    # Loss function and optimization setup\n",
    "    loss_fn = lambda params: jnp.mean((model.apply(params, X) - y) ** 2)\n",
    "    optimizer = optax.adam(0.001)\n",
    "    opt_state = optimizer.init(params)\n",
    "    \n",
    "    for epoch in range(100):  # Simple training loop\n",
    "        loss, grads = jax.value_and_grad(loss_fn)(params)\n",
    "        updates, opt_state = optimizer.update(grads, opt_state)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "    \n",
    "    return params\n",
    "\n",
    "trained_params = train_model(X_train, y_train, key)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Error Code:\n",
    "predictions = model.apply(trained_params, X_test)\n",
    "\n",
    "\n",
    "Error:\n",
    "When validating the model, the trained_params parameters used during training were incorrectly used\n",
    "\n",
    "\n",
    "Fix Guide:\n",
    "Replace the parameters used during prediction from trained_params with loaded_params after loading from the file\n",
    "\n",
    "\n",
    "Correct Code:\n",
    "predictions = model.apply(loaded_params, X_test)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Error Code:\n",
    "optimizer = optax.adam(0.001)\n",
    "\n",
    "\n",
    "Error:\n",
    "The PyTorch code uses optim.SGD(model.parameters(), lr=0.01), while the Adam optimizer is used here with a learning rate of 0.001\n",
    "\n",
    "\n",
    "Fix Guide:\n",
    "Modified to use optax.sgd with a learning rate of 0.01\n",
    "\n",
    "\n",
    "Correct Code:\n",
    "optimizer = optax.sgd(0.01)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86f9c658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions after training: [[3.3018272]\n",
      " [4.089325 ]\n",
      " [4.876823 ]]\n"
     ]
    }
   ],
   "source": [
    "#Fixed Code\n",
    "import jax\n",
    "import jax.numpy as jnp  # MODIFIED: Consistently import jax.numpy as jnp\n",
    "from jax import grad, jit, random, vmap\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "import pickle\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    \"\"\"A simple neural network model using Flax.\"\"\"\n",
    "    \n",
    "    def setup(self):\n",
    "        \"\"\"Define the layers of the model.\"\"\"\n",
    "        self.dense = nn.Dense(features=1)  # A layer with one output feature\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"Forward pass of the model.\"\"\"\n",
    "        return self.dense(x)\n",
    "\n",
    "def train_model(X, y, key):\n",
    "    \"\"\"Train the model with the given data.\"\"\"\n",
    "    model = SimpleModel()\n",
    "    params = model.init(key, X)\n",
    "    # Loss function and optimization setup\n",
    "    loss_fn = lambda params: jnp.mean((model.apply(params, X) - y) ** 2)\n",
    "    optimizer = optax.sgd(0.01)\n",
    "    opt_state = optimizer.init(params)\n",
    "    \n",
    "    for epoch in range(100):  # Simple training loop\n",
    "        loss, grads = jax.value_and_grad(loss_fn)(params)\n",
    "        updates, opt_state = optimizer.update(grads, opt_state)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "    \n",
    "    return params\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the training and evaluation of the model.\"\"\"\n",
    "    key = random.PRNGKey(42)\n",
    "    key, subkey = random.split(key)\n",
    "    X_train = random.uniform(subkey, (100, 1))\n",
    "    key, subkey = random.split(key)\n",
    "    noise = random.normal(subkey, (100, 1)) * 0.1\n",
    "    y_train = 3 * X_train + 2 + noise\n",
    "\n",
    "    # Train the model\n",
    "    trained_params = train_model(X_train, y_train, key)\n",
    "    \n",
    "    # Save model parameters to file\n",
    "    with open(\"model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(trained_params, f)\n",
    "\n",
    "    # Load model parameters from file\n",
    "    with open(\"model.pkl\", \"rb\") as f:\n",
    "        loaded_params = pickle.load(f)\n",
    "\n",
    "    # Verify the model works after loading\n",
    "    X_test = jnp.array([[0.5], [1.0], [1.5]])  # Test data\n",
    "    model = SimpleModel()  # Initialize model\n",
    "    predictions = model.apply(loaded_params, X_test)  # Get predictions\n",
    "    print(f\"Predictions after training: {predictions}\")\n",
    "\n",
    "if __name__ == \"__main__\":  # Entry point for the program\n",
    "    main()  # Execute the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d54c496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
