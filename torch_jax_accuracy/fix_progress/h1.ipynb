{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1540c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions after loading: tensor([[3.3646],\n",
      "        [4.2802],\n",
      "        [5.1959]])\n"
     ]
    }
   ],
   "source": [
    "#Input\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Create and train the model\n",
    "torch.manual_seed(42)\n",
    "model = SimpleModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "X = torch.rand(100, 1)\n",
    "y = 3 * X + 2 + torch.randn(100, 1) * 0.1\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X)\n",
    "    loss = criterion(predictions, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Save the model to a file named \"model.pth\"\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "# Load the model back from \"model.pth\"\n",
    "loaded_model = SimpleModel()\n",
    "loaded_model.load_state_dict(torch.load(\"model.pth\"))\n",
    "loaded_model.eval()\n",
    "\n",
    "# Verify the model works after loading\n",
    "X_test = torch.tensor([[0.5], [1.0], [1.5]])\n",
    "with torch.no_grad():\n",
    "    predictions = loaded_model(X_test)\n",
    "    print(f\"Predictions after loading: {predictions}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "023b1f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 9.0799\n",
      "Epoch [20/100], Loss: 5.5066\n",
      "Epoch [30/100], Loss: 3.3760\n",
      "Epoch [40/100], Loss: 2.1048\n",
      "Epoch [50/100], Loss: 1.3452\n",
      "Epoch [60/100], Loss: 0.8905\n",
      "Epoch [70/100], Loss: 0.6173\n",
      "Epoch [80/100], Loss: 0.4523\n",
      "Epoch [90/100], Loss: 0.3518\n",
      "Epoch [100/100], Loss: 0.2898\n",
      "Predictions after loading: [[3.3005486]\n",
      " [4.0336018]\n",
      " [4.7666545]]\n"
     ]
    }
   ],
   "source": [
    "#Strong LLM\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pickle\n",
    "\n",
    "\n",
    "key = jax.random.PRNGKey(42)\n",
    "# Generate 100 data points with one feature\n",
    "key, subkey = jax.random.split(key)\n",
    "X = jax.random.uniform(subkey, shape=(100, 1))\n",
    "key, subkey = jax.random.split(key)\n",
    "# Create targets: y = 3*x + 2 + noise (noise scaled by 0.1)\n",
    "y = 3 * X + 2 + 0.1 * jax.random.normal(subkey, shape=(100, 1))\n",
    "\n",
    "def predict(params, x):\n",
    "    \"\"\"Simple linear model: y = x * w + b\"\"\"\n",
    "    return jnp.dot(x, params[\"w\"]) + params[\"b\"]\n",
    "\n",
    "def loss_fn(params, X, y):\n",
    "    preds = predict(params, X)\n",
    "    return jnp.mean((preds - y) ** 2)\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "params = {\n",
    "    \"w\": 0.1 * jax.random.normal(subkey, shape=(1, 1)),\n",
    "    \"b\": jnp.zeros((1,))\n",
    "}\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(params, X, y)\n",
    "    params[\"w\"] = params[\"w\"] - lr * grads[\"w\"]\n",
    "    params[\"b\"] = params[\"b\"] - lr * grads[\"b\"]\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {float(loss):.4f}\")\n",
    "\n",
    "with open(\"model.pth\", \"wb\") as f:\n",
    "    pickle.dump(params, f)\n",
    "\n",
    "with open(\"model.pth\", \"rb\") as f:\n",
    "    loaded_params = pickle.load(f)\n",
    "\n",
    "X_test = jnp.array([[0.5], [1.0], [1.5]])\n",
    "predictions = predict(loaded_params, X_test)\n",
    "print(\"Predictions after loading:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad4a1f16",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'jax.random' has no attribute 'normal_random'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Random Numbers:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, random_numbers)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 24\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 20\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Generate a 3x3 array of random numbers\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     random_numbers \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_random_numbers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Random Numbers:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, random_numbers)\n",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m, in \u001b[0;36mgenerate_random_numbers\u001b[1;34m(shape)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_random_numbers\u001b[39m(shape):\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    Generate random numbers following a normal distribution.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m        jnp.ndarray: An array of random numbers of the specified shape.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal_random\u001b[49m(key\u001b[38;5;241m=\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m), shape\u001b[38;5;241m=\u001b[39mshape)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\jax\\_src\\deprecations.py:55\u001b[0m, in \u001b[0;36mdeprecation_getattr.<locals>.getattr\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     54\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'jax.random' has no attribute 'normal_random'"
     ]
    }
   ],
   "source": [
    "#Weak LLM\n",
    "import jax.numpy as jnp  # MODIFIED: Consistent import of jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "def generate_random_numbers(shape):\n",
    "    \"\"\"\n",
    "    Generate random numbers following a normal distribution.\n",
    "\n",
    "    Args:\n",
    "        shape (tuple): The shape of the output array.\n",
    "\n",
    "    Returns:\n",
    "        jnp.ndarray: An array of random numbers of the specified shape.\n",
    "    \"\"\"\n",
    "    return random.normal_random(key=random.PRNGKey(0), shape=shape)  # Example method to generate random numbers\n",
    "\n",
    "# Example usage of the generate_random_numbers function\n",
    "def main():\n",
    "    # Generate a 3x3 array of random numbers\n",
    "    random_numbers = generate_random_numbers((3, 3))\n",
    "    print(\"Generated Random Numbers:\\n\", random_numbers)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()  # Entry point of the program\n",
    "\n",
    "# Additional code can go here, e.g., model definition, training loops, etc.\n",
    "# Training loop\n",
    "# epochs = 1000\n",
    "# for epoch in range(epochs):\n",
    "#     model_params, optimizer_state, loss = train_step(model, X, y, optimizer_state)\n",
    "#     model = model.replace(slope=model_params)\n",
    "#     if epoch % 100 == 0:\n",
    "#         print(f'Epoch {epoch}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bface6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Error Code:\n",
    "return random.normal_random(key=random.PRNGKey(0), shape=shape)\n",
    "\n",
    "\n",
    "Error:\n",
    "module 'jax.random' has no attribute 'normal_random'\n",
    "\n",
    "\n",
    "Fix Guide:\n",
    "Replace random.normal_random with random.normal\n",
    "\n",
    "\n",
    "Correct Code:\n",
    "return random.normal(key=random.PRNGKey(0), shape=shape)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Error Code:\n",
    "import jax.numpy as jnp  # MODIFIED: Consistent import of jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "def generate_random_numbers(shape):\n",
    "    return random.normal(key=random.PRNGKey(0), shape=shape)  # Example method to generate random numbers\n",
    "\n",
    "\n",
    "Error:\n",
    "Compared with the PyTorch code, the JAX version is missing the following parts:\n",
    "Model definition\n",
    "Loss function\n",
    "Training loop\n",
    "Model saving and loading\n",
    "\n",
    "\n",
    "Fix Guide:\n",
    "Define a simple linear model, store the model parameters in a dictionary, and define a model function\n",
    "Define the loss function\n",
    "Use jax.value_and_grad to calculate the gradient and update the parameters in the training loop\n",
    "Use Python's pickle module to save and load model parameters\n",
    "\n",
    "\n",
    "Correct Code:\n",
    "import jax.numpy as jnp  # MODIFIED: Consistent import of jax.numpy as jnp\n",
    "from jax import random, value_and_grad\n",
    "import pickle\n",
    "\n",
    "def model(params, x):\n",
    "    return params['w'] * x + params['b']\n",
    "\n",
    "def mse_loss(params, x, y):\n",
    "    preds = model(params, x)\n",
    "    return jnp.mean((preds - y) ** 2)\n",
    "\n",
    "def train_step(params, x, y, learning_rate=0.01):\n",
    "    loss, grads = value_and_grad(mse_loss)(params, x, y)\n",
    "    new_params = {k: params[k] - learning_rate * grads[k] for k in params}\n",
    "    return new_params, loss\n",
    "\n",
    "def generate_random_numbers(shape):\n",
    "    return random.normal(key=random.PRNGKey(0), shape=shape)  # Example method to generate random numbers\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Error Code:\n",
    "# Example usage of the generate_random_numbers function\n",
    "def main():\n",
    "    # Generate a 3x3 array of random numbers\n",
    "    random_numbers = generate_random_numbers((3, 3))\n",
    "    print(\"Generated Random Numbers:\\n\", random_numbers)\n",
    "\n",
    "\n",
    "Error:\n",
    "Missing the part of generating training data, training loop, and saving and loading models for prediction after training\n",
    "\n",
    "\n",
    "Fix Guide:\n",
    "Use JAX's random function to generate X (uniform distribution) and noise (normal distribution), and then construct y = 3 * X + 2 + noise\n",
    "Write a training loop to update the model parameters and periodically print the loss\n",
    "Use pickle to save the trained parameters to a file and then load it from the file\n",
    "\n",
    "\n",
    "Correct Code:\n",
    "def main():\n",
    "    key = random.PRNGKey(42)\n",
    "    \n",
    "    key, subkey1, subkey2 = random.split(key, 3)\n",
    "    params = {\n",
    "        'w': random.normal(subkey1, (1,)),\n",
    "        'b': random.normal(subkey2, (1,))\n",
    "    }\n",
    "    \n",
    "    key, subkey1, subkey2 = random.split(key, 3)\n",
    "    X = random.uniform(subkey1, (100, 1))\n",
    "    noise = random.normal(subkey2, (100, 1)) * 0.1\n",
    "    y = 3 * X + 2 + noise\n",
    "    \n",
    "    epochs = 100\n",
    "    for epoch in range(epochs):\n",
    "        params, loss = train_step(params, X, y, learning_rate=0.01)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    with open(\"model.pth\", \"wb\") as f:\n",
    "        pickle.dump(params, f)\n",
    "    \n",
    "    with open(\"model.pth\", \"rb\") as f:\n",
    "        loaded_params = pickle.load(f)\n",
    "    \n",
    "    X_test = jnp.array([[0.5], [1.0], [1.5]])\n",
    "    predictions = model(loaded_params, X_test)\n",
    "    print(\"Predictions after loading:\", predictions)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aca7aeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 22.8257\n",
      "Epoch 10, Loss: 13.5925\n",
      "Epoch 20, Loss: 8.1053\n",
      "Epoch 30, Loss: 4.8441\n",
      "Epoch 40, Loss: 2.9057\n",
      "Epoch 50, Loss: 1.7532\n",
      "Epoch 60, Loss: 1.0679\n",
      "Epoch 70, Loss: 0.6600\n",
      "Epoch 80, Loss: 0.4171\n",
      "Epoch 90, Loss: 0.2723\n",
      "Predictions after loading: [[3.1789165]\n",
      " [4.227249 ]\n",
      " [5.2755823]]\n"
     ]
    }
   ],
   "source": [
    "#Fixed Code\n",
    "import jax.numpy as jnp  # MODIFIED: Consistent import of jax.numpy as jnp\n",
    "from jax import random, value_and_grad\n",
    "import pickle\n",
    "\n",
    "def model(params, x):\n",
    "    return params['w'] * x + params['b']\n",
    "\n",
    "def mse_loss(params, x, y):\n",
    "    preds = model(params, x)\n",
    "    return jnp.mean((preds - y) ** 2)\n",
    "\n",
    "def train_step(params, x, y, learning_rate=0.01):\n",
    "    loss, grads = value_and_grad(mse_loss)(params, x, y)\n",
    "    new_params = {k: params[k] - learning_rate * grads[k] for k in params}\n",
    "    return new_params, loss\n",
    "\n",
    "def generate_random_numbers(shape):\n",
    "    return random.normal(key=random.PRNGKey(0), shape=shape)  # Example method to generate random numbers\n",
    "\n",
    "def main():\n",
    "    key = random.PRNGKey(42)\n",
    "    \n",
    "    key, subkey1, subkey2 = random.split(key, 3)\n",
    "    params = {\n",
    "        'w': random.normal(subkey1, (1,)),\n",
    "        'b': random.normal(subkey2, (1,))\n",
    "    }\n",
    "    \n",
    "    key, subkey1, subkey2 = random.split(key, 3)\n",
    "    X = random.uniform(subkey1, (100, 1))\n",
    "    noise = random.normal(subkey2, (100, 1)) * 0.1\n",
    "    y = 3 * X + 2 + noise\n",
    "    \n",
    "    epochs = 100\n",
    "    for epoch in range(epochs):\n",
    "        params, loss = train_step(params, X, y, learning_rate=0.01)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    with open(\"model.pth\", \"wb\") as f:\n",
    "        pickle.dump(params, f)\n",
    "    \n",
    "    with open(\"model.pth\", \"rb\") as f:\n",
    "        loaded_params = pickle.load(f)\n",
    "    \n",
    "    X_test = jnp.array([[0.5], [1.0], [1.5]])\n",
    "    predictions = model(loaded_params, X_test)\n",
    "    print(\"Predictions after loading:\", predictions)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()  # Entry point of the program\n",
    "\n",
    "# Additional code can go here, e.g., model definition, training loops, etc.\n",
    "# Training loop\n",
    "# epochs = 1000\n",
    "# for epoch in range(epochs):\n",
    "#     model_params, optimizer_state, loss = train_step(model, X, y, optimizer_state)\n",
    "#     model = model.replace(slope=model_params)\n",
    "#     if epoch % 100 == 0:\n",
    "#         print(f'Epoch {epoch}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75c0662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
